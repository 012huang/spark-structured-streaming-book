== DataStreamWriter

`DataStreamWriter` is an interface to write the result of executing a streaming query to a link:spark-sql-streaming-sink.adoc[streaming sink].

NOTE: A streaming query is a link:spark-sql-Dataset.adoc[Dataset] with a link:spark-sql-LogicalPlan.adoc#isStreaming[streaming logical plan].

`DataStreamWriter` is available using `writeStream` method of a streaming `Dataset`.

[source, scala]
----
import org.apache.spark.sql.streaming.DataStreamWriter
import org.apache.spark.sql.Row

val streamingQuery: Dataset[Long] = ...
val writer: DataStreamWriter[Row] = streamingQuery.writeStream
----

Like the batch `DataFrameWriter`, `DataStreamWriter` has a direct support for many <<writing-dataframes-to-files, file formats>> and <<format, an extension point to plug in new formats>>.

[source, scala]
----
// see above for writer definition

// Save dataset in JSON format
writer.format("json")
----

In the end, you start the actual continuous writing of the result of executing a `Dataset` to a sink using <<start, start>> operator.

[source, scala]
----
writer.save
----

Beside the above operators, there are the following ones working with a `Dataset` as a whole.

[[methods]]
.SparkSession's Class and Instance Methods
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| <<outputMode, outputMode>>
| Specifies the output mode

| <<queryName, queryName>>
| Assigns the name of a query

| <<trigger, trigger>>
| Sets the link:spark-sql-streaming-trigger.adoc[Trigger] for how often a streaming query should be executed and the result saved.
|===

NOTE: `DataFrameWriter` is responsible for writing in a batch fashion.

=== [[outputMode]] Specifying Output Mode -- `outputMode` method

[source, scala]
----
outputMode(outputMode: OutputMode): DataStreamWriter[T]
----

`outputMode` specifies *output mode* of a streaming link:spark-sql-dataset.adoc[Dataset] which is what gets written to a link:spark-sql-streaming-sink.adoc[streaming sink] when there is a new data available.

Currently, the following output modes are supported:

* `OutputMode.Append` -- only the new rows in the streaming dataset will be written to a sink.

* `OutputMode.Complete` -- entire streaming dataset (with all the rows) will be written to a sink every time there are updates. It is supported only for streaming queries with aggregations.

=== [[queryName]] Setting Query Name -- `queryName` method

[source, scala]
----
queryName(queryName: String): DataStreamWriter[T]
----

`queryName` sets the name of a link:spark-sql-streaming-StreamingQuery.adoc[streaming query].

Internally, it is just an additional <<option, option>> with the key `queryName`.

=== [[trigger]] Setting How Often to Execute Streaming Query -- `trigger` method

[source, scala]
----
trigger(trigger: Trigger): DataStreamWriter[T]
----

`trigger` method sets the time interval of the *trigger* (batch) for a streaming query.

NOTE: `Trigger` specifies how often results should be produced by a link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery]. See link:spark-sql-streaming-trigger.adoc[Trigger].

The default trigger is link:spark-sql-streaming-trigger.adoc#ProcessingTime[ProcessingTime(0L)] that runs a streaming query as often as possible.

TIP: Consult link:spark-sql-streaming-trigger.adoc[Trigger] to learn about `Trigger` and `ProcessingTime` types.

=== [[start]] Starting Continuous Writing to Sink -- `start` methods

[source, scala]
----
start(): StreamingQuery
start(path: String): StreamingQuery  // <1>
----
<1> Sets `path` option to `path` and calls `start()`

`start` methods start a streaming query and return a link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery] object to continually write data.

NOTE: Whether or not you have to specify `path` option depends on the link:spark-sql-datasource.adoc[DataSource] in use.

Recognized options:

* `queryName` is the name of active streaming query.
* `checkpointLocation` is the directory for checkpointing.

NOTE: Define options using <<option, option>> or <<options, options>> methods.

=== [[foreach]] `foreach` method
