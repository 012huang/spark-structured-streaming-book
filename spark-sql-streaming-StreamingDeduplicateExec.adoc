== [[StreamingDeduplicateExec]] StreamingDeduplicateExec

`StreamingDeduplicateExec` is a unary physical operator (i.e. `UnaryExecNode`) that link:spark-sql-streaming-StateStoreWriter.adoc[writes state to StateStore] and link:spark-sql-streaming-WatermarkSupport.adoc[supports streaming watermark].

`StreamingDeduplicateExec` is <<creating-instance, created>> exclusively when `StreamingDeduplicationStrategy` link:spark-sql-streaming-StreamingDeduplicationStrategy.adoc#apply[plans Deduplicate unary logical operators].

[[metrics]]
.StreamingDeduplicateExec's SQLMetrics
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[numTotalStateRows]] `numTotalStateRows`
| Number of keys in the link:spark-sql-streaming-StateStore.adoc[StateStore]

| [[stateMemory]] `stateMemory`
| Memory used by the link:spark-sql-streaming-StateStore.adoc[StateStore]
|===

[[output]]
The output schema of `StreamingDeduplicateExec` is exactly the <<child, child>>'s output schema.

[[outputPartitioning]]
The output partitioning of `StreamingDeduplicateExec` is exactly the <<child, child>>'s output partitioning.

=== [[doExecute]] Executing StreamingDeduplicateExec -- `doExecute` Method

[source, scala]
----
doExecute(): RDD[InternalRow]
----

NOTE: `doExecute` is a part of `SparkPlan` contract to produce the result of a physical operator as an RDD of internal binary rows (i.e. `InternalRow`).

CAUTION: FIXME

=== [[creating-instance]] Creating StreamingDeduplicateExec Instance

`StreamingDeduplicateExec` takes the following when created:

* [[keyExpressions]] Attributes for key
* [[child]] Child physical plan (i.e. `SparkPlan`)
* [[stateInfo]] Optional `StatefulOperatorStateInfo`
* [[eventTimeWatermark]] Optional event time watermark
