== [[IncrementalExecution]] IncrementalExecution -- Streaming QueryExecution

`IncrementalExecution` is a `QueryExecution` of a streaming Dataset that allows for executing the <<logicalPlan, logical plan>> incrementally (and continuously).

[[preparations]]
`IncrementalExecution` defines <<state, state>> preparation rule to the parent ``QueryExecution``'s `preparations` that prepares streaming physical plans (using iteration-specific execution properties).

`IncrementalExecution` is <<creating-instance, created>> when:

* `StreamExecution` link:spark-sql-streaming-StreamExecution.adoc#runBatch-queryPlanning[runs a streaming batch] (and plans a streaming query)

* `ExplainCommand` is executed (for link:spark-sql-streaming-Dataset-operators.adoc#explain[explain] operator)

[[internal-registries]]
.IncrementalExecution's Internal Registries and Counters (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[planner]] `planner`
a| `SparkPlanner` with the following extra planning strategies (in the order of execution):

[[extraPlanningStrategies]]
1. link:spark-sql-streaming-StatefulAggregationStrategy.adoc[StatefulAggregationStrategy]
1. link:spark-sql-streaming-FlatMapGroupsWithStateStrategy.adoc[FlatMapGroupsWithStateStrategy]
1. link:spark-sql-streaming-StreamingRelationStrategy.adoc[StreamingRelationStrategy]
1. link:spark-sql-streaming-StreamingDeduplicationStrategy.adoc[StreamingDeduplicationStrategy]

[NOTE]
====
`planner` is used to plan (aka _convert_) an optimized logical plan into a physical plan (that is later available as `sparkPlan`).

`sparkPlan` physical plan is then prepared for execution using <<preparations, preparations>> collection of physical transformation rules. The result is later available as `executedPlan` physical plan.
====

| [[state]] `state`
| State preparation rule that transforms streaming physical plans (i.e. link:spark-sql-streaming-StateStoreSaveExec.adoc[StateStoreSaveExec], link:spark-sql-streaming-StreamingDeduplicateExec.adoc[StreamingDeduplicateExec] and link:spark-sql-streaming-FlatMapGroupsWithStateExec.adoc[FlatMapGroupsWithStateExec]) to add missing properties that are iteration-specific, i.e. the current batch.

Used when `IncrementalExecution` <<preparations, prepares a physical plan>> (i.e. `SparkPlan`) for execution.

| [[statefulOperatorId]] `statefulOperatorId`
a| Java's `AtomicInteger`

* `0` when `IncrementalExecution` is <<creating-instance, created>>

* Incremented...FIXME
|===

=== [[creating-instance]] Creating IncrementalExecution Instance

`IncrementalExecution` takes the following when created:

* [[sparkSession]] `SparkSession`
* [[logicalPlan]] Logical plan
* [[outputMode]] link:spark-sql-streaming-OutputMode.adoc[OutputMode]
* [[checkpointLocation]] Checkpoint directory
* [[runId]] Run id
* [[currentBatchId]] Current batch id
* [[offsetSeqMetadata]] `OffsetSeqMetadata`

`IncrementalExecution` initializes the <<internal-registries, internal registries and counters>>.
