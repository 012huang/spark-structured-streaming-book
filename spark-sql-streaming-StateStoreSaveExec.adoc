== [[StateStoreSaveExec]] StateStoreSaveExec Unary Physical Operator for Saving State of Streaming Aggregates

`StateStoreSaveExec` is a unary physical operator (i.e. `UnaryExecNode`) that link:spark-sql-streaming-StateStoreWriter.adoc[writes a streaming state to a StateStore] with link:spark-sql-streaming-WatermarkSupport.adoc[support for streaming watermark].

`StateStoreSaveExec` is <<creating-instance, created>> exclusively when `StatefulAggregationStrategy` link:spark-sql-streaming-StatefulAggregationStrategy.adoc#apply[plans streaming Aggregate logical operators] (aka _streaming aggregates_).

.StateStoreSaveExec and StatefulAggregationStrategy
image::images/StateStoreSaveExec-StatefulAggregationStrategy.png[align="center"]

[NOTE]
====
`Aggregate` logical operator is the result of:

* `RelationalGroupedDataset` aggregations, i.e. `agg` and  `pivot` operators

* `KeyValueGroupedDataset` aggregations, i.e. `mapGroups`, `flatMapGroups`, `mapGroupsWithState`, `flatMapGroupsWithState`, `reduceGroups`, and `agg`, `cogroup` operators

* SQL's `GROUP BY` clause (possibly with `WITH CUBE` or `WITH ROLLUP`)
====

The optional properties, i.e. <<stateInfo, StatefulOperatorStateInfo>>, <<outputMode, output mode>>, and <<eventTimeWatermark, event time watermark>>, are undefined when `StateStoreSaveExec` is <<creating-instance, created>>. `StateStoreSaveExec` is updated to hold their batch-specific execution properties every time `IncrementalExecution` link:spark-sql-streaming-IncrementalExecution.adoc#preparations[prepares a streaming physical plan for execution] (and link:spark-sql-streaming-IncrementalExecution.adoc#state[state] preparation rule is executed when `StreamExecution` link:spark-sql-streaming-StreamExecution.adoc#runBatch-queryPlanning[plans a streaming query] for a streaming batch).

.StateStoreSaveExec and IncrementalExecution
image::images/StateStoreSaveExec-IncrementalExecution.png[align="center"]

When <<doExecute, executed>>, `StateStoreSaveExec` link:spark-sql-streaming-StateStoreOps.adoc#mapPartitionsWithStateStore[creates a StateStoreRDD to map over partitions] with `storeUpdateFunction` that manages the `StateStore`.

.StateStoreSaveExec creates StateStoreRDD
image::images/StateStoreSaveExec-StateStoreRDD.png[align="center"]

[source, scala]
----
scala> spark.version
res0: String = 2.3.0-SNAPSHOT

// START: Only for easier debugging
// The state is then only for one partition
// which should make monitoring it easier
import org.apache.spark.sql.internal.SQLConf.SHUFFLE_PARTITIONS
spark.sessionState.conf.setConf(SHUFFLE_PARTITIONS, 1)
scala> spark.sessionState.conf.numShufflePartitions
res2: Int = 1
// END: Only for easier debugging

val counts = spark.
  readStream.
  format("rate").
  load.
  groupBy(window($"timestamp", "5 seconds") as "group").
  agg(count("value") as "value_count") // <-- creates a Aggregate logical operator
scala> counts.explain(true)
== Parsed Logical Plan ==
'Aggregate [timewindow('timestamp, 5000000, 5000000, 0) AS window#5 AS group#6], [timewindow('timestamp, 5000000, 5000000, 0) AS window#5 AS group#6, count('value) AS value_count#12]
+- StreamingRelation DataSource(org.apache.spark.sql.SparkSession@489cbbcb,rate,List(),None,List(),None,Map(),None), rate, [timestamp#0, value#1L]
...
== Physical Plan ==
*HashAggregate(keys=[window#18], functions=[count(value#1L)], output=[group#6, value_count#12L])
+- StateStoreSave [window#18], StatefulOperatorStateInfo(<unknown>,9a6d381e-1066-4e2c-abd2-27884a6c2d16,0,0), Append, 0
   +- *HashAggregate(keys=[window#18], functions=[merge_count(value#1L)], output=[window#18, count#20L])
      +- StateStoreRestore [window#18], StatefulOperatorStateInfo(<unknown>,9a6d381e-1066-4e2c-abd2-27884a6c2d16,0,0)
         +- *HashAggregate(keys=[window#18], functions=[merge_count(value#1L)], output=[window#18, count#20L])
            +- Exchange hashpartitioning(window#18, 1)
               +- *HashAggregate(keys=[window#18], functions=[partial_count(value#1L)], output=[window#18, count#20L])
                  +- *Project [named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) as double) = (cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) THEN (CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) END + 0) - 1) * 5000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) as double) = (cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) THEN (CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#0, TimestampType, LongType) - 0) as double) / 5000000.0)) END + 0) - 1) * 5000000) + 5000000), LongType, TimestampType)) AS window#18, value#1L]
                     +- *Filter isnotnull(timestamp#0)
                        +- StreamingRelation rate, [timestamp#0, value#1L]

// Start the query and hence execute StateStoreSaveExec
import scala.concurrent.duration._
import org.apache.spark.sql.streaming.{OutputMode, Trigger}
val sq = counts.
  writeStream.
  format("console").
  option("truncate", false).
  trigger(Trigger.ProcessingTime(1.hour)). // <-- should be enough time for exploration
  outputMode(OutputMode.Complete).
  start

// wait till the first batch which should happen right after start

import org.apache.spark.sql.execution.streaming._
val streamingBatch = sq.asInstanceOf[StreamingQueryWrapper].streamingQuery.lastExecution

scala> println(streamingBatch.logical.numberedTreeString)
00 Aggregate [window#13], [window#13 AS group#6, count(value#25L) AS value_count#12L]
01 +- Filter isnotnull(timestamp#24)
02    +- Project [named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) END + cast(0 as bigint)) - cast(1 as bigint)) * 5000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#24, TimestampType, LongType) - 0) as double) / cast(5000000 as double))) END + cast(0 as bigint)) - cast(1 as bigint)) * 5000000) + 0) + 5000000), LongType, TimestampType)) AS window#13, timestamp#24, value#25L]
03       +- LogicalRDD [timestamp#24, value#25L], true

// Note the number of partitions
// 200 is the default, but we have changed it above
scala> println(streamingBatch.toRdd.toDebugString)
(1) MapPartitionsRDD[20] at toRdd at <console>:38 []
 |  StateStoreRDD[19] at toRdd at <console>:38 []
 |  MapPartitionsRDD[18] at toRdd at <console>:38 []
 |  StateStoreRDD[17] at toRdd at <console>:38 []
 |  MapPartitionsRDD[16] at toRdd at <console>:38 []
 |  ShuffledRowRDD[4] at start at <console>:36 []
 +-(0) MapPartitionsRDD[3] at start at <console>:36 []
    |  MapPartitionsRDD[2] at start at <console>:36 []
    |  MapPartitionsRDD[1] at start at <console>:36 []
    |  EmptyRDD[0] at start at <console>:36 []

scala> spark.sessionState.conf.numShufflePartitions
res6: Int = 1
----

.StateStoreSaveExec and StateStoreRDD (after streamingBatch.toRdd.count)
image::images/StateStoreSaveExec-StateStoreRDD-count.png[align="center"]

[NOTE]
====
The number of partitions of link:spark-sql-streaming-StateStoreOps.adoc#mapPartitionsWithStateStore[StateStoreRDD] (and hence the number of Spark tasks) is what was defined for the <<child, child>> physical plan.

There will be that many `StateStores` as there are partitions in `StateStoreRDD`.
====

NOTE: `StateStoreSaveExec` <<doExecute, works>> differently per output mode.

[source, scala]
----
// START: Only for easier debugging
// The state is then only for one partition
// which should make monitoring it easier
import org.apache.spark.sql.internal.SQLConf.SHUFFLE_PARTITIONS
spark.sessionState.conf.setConf(SHUFFLE_PARTITIONS, 1)
scala> spark.sessionState.conf.numShufflePartitions
res0: Int = 1
// END: Only for easier debugging

// Read datasets from a Kafka topic
// ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0-SNAPSHOT
val valuesPerGroup = spark.
  readStream.
  format("kafka").
  option("subscribe", "topic1").
  option("kafka.bootstrap.servers", "localhost:9092").
  load.
  withColumn("tokens", split('value, ",")).
  withColumn("group", 'tokens(0)).
  withColumn("value", 'tokens(1) cast "int").
  select("group", "value").
  groupBy($"group").
  agg(collect_list("value") as "values").
  orderBy($"group".asc)

// Note that StatefulOperatorStateInfo is mostly generic
// since no batch-specific values are currently available
// only after the first streaming batch
scala> valuesPerGroup.explain
== Physical Plan ==
*Sort [group#25 ASC NULLS FIRST], true, 0
+- Exchange rangepartitioning(group#25 ASC NULLS FIRST, 1)
   +- ObjectHashAggregate(keys=[group#25], functions=[collect_list(value#36, 0, 0)])
      +- Exchange hashpartitioning(group#25, 1)
         +- StateStoreSave [group#25], StatefulOperatorStateInfo(<unknown>,e554670a-0866-4c62-b2c0-4c98b5f22481,0,0), Append, 0
            +- ObjectHashAggregate(keys=[group#25], functions=[merge_collect_list(value#36, 0, 0)])
               +- Exchange hashpartitioning(group#25, 1)
                  +- StateStoreRestore [group#25], StatefulOperatorStateInfo(<unknown>,e554670a-0866-4c62-b2c0-4c98b5f22481,0,0)
                     +- ObjectHashAggregate(keys=[group#25], functions=[merge_collect_list(value#36, 0, 0)])
                        +- Exchange hashpartitioning(group#25, 1)
                           +- ObjectHashAggregate(keys=[group#25], functions=[partial_collect_list(value#36, 0, 0)])
                              +- *Project [split(cast(value#1 as string), ,)[0] AS group#25, cast(split(cast(value#1 as string), ,)[1] as int) AS value#36]
                                 +- StreamingRelation kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

// Start the query and hence StateStoreSaveExec
// Use Complete output mode
import scala.concurrent.duration._
import org.apache.spark.sql.streaming.{OutputMode, Trigger}
val sq = valuesPerGroup.
  writeStream.
  format("console").
  option("truncate", false).
  trigger(Trigger.ProcessingTime(10.seconds)).
  outputMode(OutputMode.Complete).
  start

-------------------------------------------
Batch: 0
-------------------------------------------
+-----+------+
|group|values|
+-----+------+
+-----+------+
...
17/08/27 22:47:48 INFO StreamExecution: Streaming query made progress: {
...
  "stateOperators" : [ {
    "numRowsTotal" : 0,
    "numRowsUpdated" : 0,
    "memoryUsedBytes" : 12198
  } ],
...
17/08/27 22:47:48 DEBUG StreamExecution: batch 0 committed

-------------------------------------------
Batch: 1
-------------------------------------------
+-----+------+
|group|values|
+-----+------+
|0    |[1]   |
+-----+------+
...
17/08/27 22:48:02 INFO StreamExecution: Streaming query made progress: {
...
  "stateOperators" : [ {
    "numRowsTotal" : 1,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 324
  } ],
...

-------------------------------------------
Batch: 2
-------------------------------------------
+-----+------+
|group|values|
+-----+------+
|0    |[2, 1]|
+-----+------+

...
17/08/27 22:55:00 INFO StreamExecution: Streaming query made progress: {
...
  "stateOperators" : [ {
    "numRowsTotal" : 1,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 324
  } ],
...

-------------------------------------------
Batch: 3
-------------------------------------------
+-----+------+
|group|values|
+-----+------+
|0    |[2, 1]|
|1    |[1]   |
+-----+------+

...
17/08/27 22:57:10 INFO StreamExecution: Streaming query made progress: {
...
  "stateOperators" : [ {
    "numRowsTotal" : 2,
    "numRowsUpdated" : 1,
    "memoryUsedBytes" : 572
  } ],
...

// In the end...
sq.stop
----

[[metrics]]
.StateStoreSaveExec's SQLMetrics
[cols="1,1,2",options="header",width="100%"]
|===
| Key
| Name (in UI)
| Description

| [[allUpdatesTimeMs]] `allUpdatesTimeMs`
| total time to update rows
|

| [[allRemovalsTimeMs]] `allRemovalsTimeMs`
| total time to remove rows
|

| [[commitTimeMs]] `commitTimeMs`
| time to commit changes
|

| [[numOutputRows]] `numOutputRows`
| number of output rows
|

| [[numTotalStateRows]] `numTotalStateRows`
| number of total state rows
| Number of the state keys in the link:spark-sql-streaming-StateStore.adoc[state store]

Corresponds to `numRowsTotal` in `stateOperators` in link:spark-sql-streaming-ProgressReporter.adoc#StreamingQueryProgress[StreamingQueryProgress] (and is available as `sq.lastProgress.stateOperators(0).numRowsTotal`).

| [[numUpdatedStateRows]] `numUpdatedStateRows`
| number of updated state rows
|

| [[stateMemory]] `stateMemory`
| memory used by state
| Memory used by the link:spark-sql-streaming-StateStore.adoc[StateStore]
|===

.StateStoreSaveExec in web UI (Details for Query)
image::images/StateStoreSaveExec-webui-query-details.png[align="center"]

When <<doExecute, executed>>, `StateStoreSaveExec` executes the <<child, child>> physical operator and link:spark-sql-streaming-StateStoreOps.adoc#mapPartitionsWithStateStore[creates a StateStoreRDD] (with `storeUpdateFunction` specific to the output mode).

[[output]]
The output schema of `StateStoreSaveExec` is exactly the <<child, child>>'s output schema.

[[outputPartitioning]]
The output partitioning of `StateStoreSaveExec` is exactly the <<child, child>>'s output partitioning.

=== [[doExecute]] Executing StateStoreSaveExec -- `doExecute` Method

[source, scala]
----
doExecute(): RDD[InternalRow]
----

NOTE: `doExecute` is a part of `SparkPlan` contract to produce the result of a physical operator as an RDD of internal binary rows (i.e. `InternalRow`).

Internally, `doExecute` initializes link:spark-sql-streaming-StateStoreWriter.adoc#metrics[metrics].

NOTE: `doExecute` requires that the optional <<outputMode, outputMode>> is at this point defined (that should happen when `IncrementalExecution` link:spark-sql-streaming-IncrementalExecution.adoc#preparations[prepares a streaming aggregation for execution]).

`doExecute` executes <<child, child>> physical operator and link:spark-sql-streaming-StateStoreOps.adoc#mapPartitionsWithStateStore[creates a StateStoreRDD] with `storeUpdateFunction` that:

1. Generates an unsafe projection to access the key field (using <<keyExpressions, keyExpressions>> and the output schema of <<child, child>>).

1. Branches off per <<outputMode, output mode>>.

[[doExecute-branches]]
.doExecute's Behaviour per Output Mode
[cols="1,2",options="header",width="100%"]
|===
| Output Mode
| doExecute's Behaviour

| [[doExecute-Append]] `Append`
a|

Filters out all late aggregate rows (per link:spark-sql-streaming-WatermarkSupport.adoc#watermarkPredicateForData[watermark]) and link:spark-sql-streaming-StateStore.adoc#put[stores all the "young" rows in the state store] (eagerly, i.e. before returning an iterator). Returns an iterator that link:spark-sql-streaming-StateStore.adoc#remove[removes the late rows from the state store]. In the end, link:spark-sql-streaming-StateStore.adoc#commit[commits the state updates].

CAUTION: FIXME Example of Append with StateStoreSaveExec (and mandatory watermark)

---

1. Uses link:spark-sql-streaming-WatermarkSupport.adoc#watermarkPredicateForData[watermarkPredicateForData] predicate to exclude matching rows and (like in <<doExecute-Complete, Complete>> output mode) link:spark-sql-streaming-StateStore.adoc#put[stores all the remaining rows] in `StateStore`.

1. (like in <<doExecute-Complete, Complete>> output mode) While storing the rows, increments <<numUpdatedStateRows, numUpdatedStateRows>> metric (for every row) and records the total time in <<allUpdatesTimeMs, allUpdatesTimeMs>> metric.

1. link:spark-sql-streaming-StateStore.adoc#getRange[Takes all the rows] from `StateStore` and returns a `NextIterator` that:

* In `getNext`, finds the first row that matches link:spark-sql-streaming-WatermarkSupport.adoc#watermarkPredicateForKeys[watermarkPredicateForKeys] predicate, link:spark-sql-streaming-StateStore.adoc#remove[removes it] from `StateStore`, and returns it back.
+
If no row was found, `getNext` also marks the iterator as finished.

* In `close`, records the time to iterate over all the rows in <<allRemovalsTimeMs, allRemovalsTimeMs>> metric, link:spark-sql-streaming-StateStore.adoc#commit[commits the updates] to `StateStore` followed by recording the time in <<commitTimeMs, commitTimeMs>> metric and link:spark-sql-streaming-StateStoreWriter.adoc#setStoreMetrics[recording StateStore metrics].

| [[doExecute-Complete]] `Complete`
a|

1. Takes all `UnsafeRow` rows (from the parent iterator)

1. link:spark-sql-streaming-StateStore.adoc#put[Stores the rows by key in the state store] eagerly (i.e. all rows that are available in the parent iterator before proceeding)

1. link:spark-sql-streaming-StateStore.adoc#commit[Commits the state updates]

1. In the end, `doExecute` link:spark-sql-streaming-StateStore.adoc#iterator[reads the key-row pairs from the state store] and passes the rows along (i.e. to the following physical operator)

The number of keys stored in the state store is recorded in <<numUpdatedStateRows, numUpdatedStateRows>> metric.

NOTE: In `Complete` output mode <<numOutputRows, numOutputRows>> metric is exactly <<numTotalStateRows, numTotalStateRows>> metric.

---

1. link:spark-sql-streaming-StateStore.adoc#put[Stores all rows] (as `UnsafeRow`) in `StateStore`.

1. While storing the rows, increments <<numUpdatedStateRows, numUpdatedStateRows>> metric (for every row) and records the total time in <<allUpdatesTimeMs, allUpdatesTimeMs>> metric.

1. Records `0` in <<allRemovalsTimeMs, allRemovalsTimeMs>> metric.

1. link:spark-sql-streaming-StateStore.adoc#commit[Commits the state updates] to `StateStore` and records the time in <<commitTimeMs, commitTimeMs>> metric.

1. link:spark-sql-streaming-StateStoreWriter.adoc#setStoreMetrics[Records StateStore metrics].

1. In the end, link:spark-sql-streaming-StateStore.adoc#iterator[takes all the rows stored] in `StateStore` and increments <<numOutputRows, numOutputRows>> metric.

| [[doExecute-Update]] `Update`
a|

Returns an iterator that filters out late aggregate rows (per link:spark-sql-streaming-WatermarkSupport.adoc#watermarkPredicateForData[watermark] if defined) and link:spark-sql-streaming-StateStore.adoc#put[stores the "young" rows in the state store] (one by one, i.e. every `next`). With no more rows available, that link:spark-sql-streaming-StateStore.adoc#remove[removes the late rows from the state store] (all at once) and link:spark-sql-streaming-StateStore.adoc#commit[commits the state updates].

CAUTION: FIXME Example of Update with StateStoreSaveExec (and optional watermark)

---

Returns `Iterator` of rows that uses link:spark-sql-streaming-WatermarkSupport.adoc#watermarkPredicateForData[watermarkPredicateForData] predicate to filter out late rows.

In `hasNext`, when rows are no longer available:

1. Records the total time to iterate over all the rows in <<allUpdatesTimeMs, allUpdatesTimeMs>> metric.

1. link:spark-sql-streaming-WatermarkSupport.adoc#removeKeysOlderThanWatermark[removeKeysOlderThanWatermark] and records the time in <<allRemovalsTimeMs, allRemovalsTimeMs>> metric.

1. link:spark-sql-streaming-StateStore.adoc#commit[Commits the updates] to `StateStore` and records the time in <<commitTimeMs, commitTimeMs>> metric.

1. link:spark-sql-streaming-StateStoreWriter.adoc#setStoreMetrics[Records StateStore metrics].

In `next`, link:spark-sql-streaming-StateStore.adoc#put[stores a row] in `StateStore` and increments <<numOutputRows, numOutputRows>> and <<numUpdatedStateRows, numUpdatedStateRows>> metrics.
|===

`doExecute` reports a `UnsupportedOperationException` when executed with an invalid output mode.

```
Invalid output mode: [outputMode]
```

=== [[creating-instance]] Creating StateStoreSaveExec Instance

`StateStoreSaveExec` takes the following when created:

* [[keyExpressions]] Key attributes (as used for aggregation in link:spark-sql-streaming-Dataset-operators.adoc#groupBy[groupBy] operator)
* [[stateInfo]] `StatefulOperatorStateInfo`
* [[outputMode]] link:spark-sql-streaming-OutputMode.adoc[Output mode]
* [[eventTimeWatermark]] Event time watermark (as `long` number)
* [[child]] Child physical plan (i.e. `SparkPlan`)
