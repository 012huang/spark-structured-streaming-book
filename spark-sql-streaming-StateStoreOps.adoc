== [[StateStoreOps]] StateStoreOps -- Extension Methods for Creating StateStoreRDD

`StateStoreOps` is a *Scala implicit class* to <<mapPartitionsWithStateStore, create>> `StateStoreRDD` when the following physical operators are executed:

* link:spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#doExecute[FlatMapGroupsWithStateExec]

* link:spark-sql-streaming-StateStoreRestoreExec.adoc#doExecute[StateStoreRestoreExec]

* link:spark-sql-streaming-StateStoreSaveExec.adoc#doExecute[StateStoreSaveExec]

* link:spark-sql-streaming-StreamingDeduplicateExec.adoc#doExecute[StreamingDeduplicateExec]

NOTE: http://docs.scala-lang.org/overviews/core/implicit-classes.html[Implicit Classes] are a language feature in Scala for *implicit conversions* with *extension methods* for existing types.

=== [[mapPartitionsWithStateStore]] Creating StateStoreRDD (with storeUpdateFunction Aborting StateStore When Task Fails) -- `mapPartitionsWithStateStore` Method

[source, scala]
----
mapPartitionsWithStateStore[U](
  sqlContext: SQLContext,
  stateInfo: StatefulOperatorStateInfo,
  keySchema: StructType,
  valueSchema: StructType,
  indexOrdinal: Option[Int])(
  storeUpdateFunction: (StateStore, Iterator[T]) => Iterator[U]): StateStoreRDD[T, U] // <1>
mapPartitionsWithStateStore[U](
  stateInfo: StatefulOperatorStateInfo,
  keySchema: StructType,
  valueSchema: StructType,
  indexOrdinal: Option[Int],
  sessionState: SessionState,
  storeCoordinator: Option[StateStoreCoordinatorRef])(
  storeUpdateFunction: (StateStore, Iterator[T]) => Iterator[U]): StateStoreRDD[T, U]
----
<1> Uses `sqlContext.streams.stateStoreCoordinator` to access `StateStoreCoordinator`

Internally, `mapPartitionsWithStateStore` requests `SparkContext` to clean `storeUpdateFunction` function.

NOTE: `mapPartitionsWithStateStore` uses the enclosing RDD to access the current `SparkContext`.

NOTE: *Function Cleaning* is to clean a closure from unreferenced variables before it is serialized and sent to tasks. `SparkContext` reports a `SparkException` when the closure is not serializable.

`mapPartitionsWithStateStore` creates a (wrapper) function to link:spark-sql-streaming-StateStore.adoc#abort[abort] the `StateStore` in case of error (which is to make sure that the `StateStore` has been link:spark-sql-streaming-StateStore.adoc#hasCommitted[committed] in the end).

NOTE: `mapPartitionsWithStateStore` uses `TaskCompletionListener` to be notified when a task has finished.

`mapPartitionsWithStateStore` returns a link:spark-sql-streaming-StateStoreRDD.adoc[StateStoreRDD].

[NOTE]
====
`mapPartitionsWithStateStore` is used when the following physical operators are executed:

* link:spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#doExecute[FlatMapGroupsWithStateExec]

* link:spark-sql-streaming-StateStoreRestoreExec.adoc#doExecute[StateStoreRestoreExec]

* link:spark-sql-streaming-StateStoreSaveExec.adoc#doExecute[StateStoreSaveExec]

* link:spark-sql-streaming-StreamingDeduplicateExec.adoc#doExecute[StreamingDeduplicateExec]
====
