== [[StreamingQueryManager]] StreamingQueryManager -- Streaming Query Management

`StreamingQueryManager` is the management interface for link:spark-sql-streaming-StreamingQuery.adoc[continuous queries] (per `SparkSession`).

`StreamingQueryManager` manages all continuous structured queries per `SparkSession` that is available using `SparkSession.streams` operator.

[source, scala]
----
val spark: SparkSession = ...
val queries = spark.streams
----

`StreamingQueryManager` is created exclusively when `SessionState` is created (that is available as `sessionState` property of `SparkSession`).

TIP: Refer to the https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-SessionState.html[Mastering Apache Spark 2] gitbook to learn about `SessionState`.

[[internal-registries]]
.StreamingQueryManager's Internal Registries and Counters (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[stateStoreCoordinator]] `stateStoreCoordinator`
|

| [[listenerBus]] `listenerBus`
a| link:spark-sql-streaming-StreamingQueryListenerBus.adoc[StreamingQueryListenerBus] (for the current <<sparkSession, SparkSession>>)

Used to:

* <<addListener, register>> or <<removeListener, deregister>> a `StreamingQueryListener`

* <<postListenerEvent, Post a streaming event>>

| [[activeQueries]] `activeQueries`
| Registry of `StreamingQueryWrapper` per id

Used in <<active, active>>, <<get, get>>, <<startQuery, startQuery>> and <<notifyQueryTermination, notifyQueryTermination>>.
|===

=== [[notifyQueryTermination]] `notifyQueryTermination` Internal Method

CAUTION: FIXME

=== [[createQuery]] Creating StreamingQueryWrapper (Serializable StreamingQuery) -- `createQuery` Internal Method

[source, scala]
----
createQuery(
  userSpecifiedName: Option[String],
  userSpecifiedCheckpointLocation: Option[String],
  df: DataFrame,
  sink: Sink,
  outputMode: OutputMode,
  useTempCheckpointLocation: Boolean,
  recoverFromCheckpointLocation: Boolean,
  trigger: Trigger,
  triggerClock: Clock): StreamingQueryWrapper
----

CAUTION: FIXME

[NOTE]
====
`recoverFromCheckpointLocation` flag corresponds to `recoverFromCheckpointLocation` flag that `StreamingQueryManager` uses to <<startQuery, start a streaming query>> and which is enabled by default (and is in fact the only place where `createQuery` is used).

* `memory` sink has the flag enabled for link:spark-sql-streaming-OutputMode.adoc#Complete[Complete] output mode only

* `foreach` sink has the flag always enabled

* `console` sink has the flag always disabled

* all other sinks have the flag always enabled
====

NOTE: `userSpecifiedName` corresponds to `queryName` option (that can be defined using ``DataStreamWriter``'s link:spark-sql-streaming-DataStreamWriter.adoc#queryName[queryName] method) while `userSpecifiedCheckpointLocation` is `checkpointLocation` option.

NOTE: `createQuery` is used exclusively when `StreamingQueryManager` <<startQuery, starts executing a streaming query>>.

=== Initialization

`StreamingQueryManager` manages the following instances:

* link:spark-sql-streaming-StateStoreCoordinatorRef.adoc[StateStoreCoordinatorRef] (as `stateStoreCoordinator`)
* link:spark-sql-streaming-StreamingQueryListenerBus.adoc[StreamingQueryListenerBus] (as `listenerBus`)
* `activeQueries` which is a mutable mapping between query names and `StreamingQuery` objects.

=== [[startQuery]] Starting Execution of Streaming Query -- `startQuery` Internal Method

[source, scala]
----
startQuery(
  userSpecifiedName: Option[String],
  userSpecifiedCheckpointLocation: Option[String],
  df: DataFrame,
  sink: Sink,
  outputMode: OutputMode,
  useTempCheckpointLocation: Boolean = false,
  recoverFromCheckpointLocation: Boolean = true,
  trigger: Trigger = ProcessingTime(0),
  triggerClock: Clock = new SystemClock()): StreamingQuery
----

`startQuery` starts a link:spark-sql-streaming-StreamingQuery.adoc[streaming query].

NOTE: `trigger` defaults to `0` milliseconds (as link:spark-sql-streaming-Trigger.adoc#ProcessingTime[ProcessingTime(0)]).

Internally, `startQuery` first <<createQuery, creates a streaming query>>, registers it in <<activeQueries, activeQueries>> internal registry and link:spark-sql-streaming-StreamExecution.adoc#start[starts the query].

In the end, `startQuery` returns the query (as part of the fluent API so you can chain operators) or reports the exception that was reported when starting the query.

`startQuery` reports a `IllegalArgumentException` when there is another query registered under `name`. `startQuery` looks it up in <<activeQueries, activeQueries>> internal registry.

```
Cannot start query with name [name] as a query with that name is already active
```

`startQuery` reports a `IllegalStateException` when a query is started again from checkpoint. `startQuery` looks it up in <<activeQueries, activeQueries>> internal registry.

```
Cannot start query with id [id] as another query with same id is already active.
Perhaps you are attempting to restart a query from checkpoint that is already active.
```

NOTE: `startQuery` is used exclusively when `DataStreamWriter` is link:spark-sql-streaming-DataStreamWriter.adoc#start[started].

=== [[active]] Return All Active Continuous Queries per SQLContext -- `active` Method

[source, scala]
----
active: Array[StreamingQuery]
----

`active` method returns a collection of link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery] instances for the current `SQLContext`.

=== [[get]] Getting Active Continuous Query By Name -- `get` Method

[source, scala]
----
get(name: String): StreamingQuery
----

`get` method returns a link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery] by `name`.

It may throw an `IllegalArgumentException` when no StreamingQuery exists for the `name`.

```
java.lang.IllegalArgumentException: There is no active query with name hello
  at org.apache.spark.sql.StreamingQueryManager$$anonfun$get$1.apply(StreamingQueryManager.scala:59)
  at org.apache.spark.sql.StreamingQueryManager$$anonfun$get$1.apply(StreamingQueryManager.scala:59)
  at scala.collection.MapLike$class.getOrElse(MapLike.scala:128)
  at scala.collection.AbstractMap.getOrElse(Map.scala:59)
  at org.apache.spark.sql.StreamingQueryManager.get(StreamingQueryManager.scala:58)
  ... 49 elided
```

=== [[addListener]][[removeListener]] StreamingQueryListener Management by Adding or Removing Listeners -- `addListener` and `removeListener` Methods

* `addListener(listener: StreamingQueryListener): Unit` adds `listener` to the internal `listenerBus`.
* `removeListener(listener: StreamingQueryListener): Unit` removes `listener` from the internal `listenerBus`.

=== [[lastTerminatedQuery]] `lastTerminatedQuery` Internal Barrier

CAUTION: FIXME Why is `lastTerminatedQuery` needed?

Used in:

* `awaitAnyTermination`
* `awaitAnyTermination(timeoutMs: Long)`

They all wait `10` millis before doing the check of `lastTerminatedQuery` being non-null.

It is set in:

* `resetTerminated()` resets `lastTerminatedQuery`, i.e. sets it to `null`.
* `notifyQueryTermination(terminatedQuery: StreamingQuery)` sets `lastTerminatedQuery` to be `terminatedQuery` and notifies all the threads that wait on `awaitTerminationLock`.
+
It is called from link:spark-sql-streaming-StreamExecution.adoc#runBatches[StreamExecution.runBatches].

=== [[postListenerEvent]] Posting StreamingQueryListener Event to StreamingQueryListenerBus -- `postListenerEvent` Method

[source, scala]
----
postListenerEvent(event: StreamingQueryListener.Event): Unit
----

`postListenerEvent` simply posts the input `event` to <<listenerBus, StreamingQueryListenerBus>> (in the current `SparkSession`).

.StreamingQueryManager Propagates StreamingQueryListener Events
image::images/StreamingQueryManager-postListenerEvent.png[align="center"]

NOTE: `postListenerEvent` is used exclusively when `StreamExecution` link:spark-sql-streaming-StreamExecution.adoc#postEvent[posts a streaming event].

=== [[creating-instance]] Creating StreamingQueryManager Instance

`StreamingQueryManager` takes the following when created:

* [[sparkSession]] `SparkSession`

`StreamingQueryManager` initializes the <<internal-registries, internal registries and counters>>.
